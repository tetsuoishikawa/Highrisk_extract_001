import streamlit as st
from transformers import AutoTokenizer, AutoModelForTokenClassification
import torch
import torch.nn.functional as F

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®èª­ã¿è¾¼ã¿ï¼ˆåˆå›ã®ã¿ï¼‰
@st.cache_resource
def load_model():
    model_name = "Tetsuo3003/highrisk_medical_japanese"
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)
    model = AutoModelForTokenClassification.from_pretrained(model_name)
    return tokenizer, model

tokenizer, model = load_model()
label_list = model.config.id2label

# ãƒ©ãƒ™ãƒ«ã® B- / I- ã‚’å–ã‚Šé™¤ã
def strip_label_prefix(label):
    return label.replace("B-", "").replace("I-", "")

# ãƒ©ãƒ™ãƒ«ãŒåŒã˜ã‚‚ã®ã‚’ãƒãƒ¼ã‚¸ï¼ˆB- / I- ç„¡è¦–ï¼‰
def merge_same_label_entities(tokens, labels, scores):
    merged = []
    current_tokens = []
    current_label = None
    current_scores = []

    for token, label, score in zip(tokens, labels, scores):
        if token in tokenizer.all_special_tokens:
            continue
        token_stripped = token.lstrip("â–")
        clean_label = strip_label_prefix(label)

        if clean_label == "O":
            if current_tokens:
                word = "".join(current_tokens)
                avg_score = sum(current_scores) / len(current_scores)
                merged.append((word, current_label, avg_score))
                current_tokens = []
                current_scores = []
                current_label = None
            continue

        if clean_label == current_label:
            current_tokens.append(token_stripped)
            current_scores.append(score)
        else:
            if current_tokens:
                word = "".join(current_tokens)
                avg_score = sum(current_scores) / len(current_scores)
                merged.append((word, current_label, avg_score))
            current_tokens = [token_stripped]
            current_scores = [score]
            current_label = clean_label

    if current_tokens:
        word = "".join(current_tokens)
        avg_score = sum(current_scores) / len(current_scores)
        merged.append((word, current_label, avg_score))
    return merged

# æ¨è«–å‡¦ç†
def ner_predict(text):
    encoded = tokenizer(text, return_tensors="pt", truncation=True)
    input_ids = encoded["input_ids"]
    with torch.no_grad():
        logits = model(**encoded).logits

    probs = F.softmax(logits, dim=-1)
    scores, predictions = torch.max(probs, dim=2)

    token_ids = input_ids.squeeze().tolist()
    tokens = tokenizer.convert_ids_to_tokens(token_ids)
    predicted_labels = [label_list[pred.item()] for pred in predictions.squeeze()]
    confidence_scores = scores.squeeze().tolist()

    merged = merge_same_label_entities(tokens, predicted_labels, confidence_scores)
    return merged

# --- Streamlit UI ---

st.title("ğŸ©ºãƒã‚¤ãƒªã‚¹ã‚¯æŠ½å‡ºï¼ˆhighrisk_medical_japaneseï¼‰")

input_text = st.text_area("FTã—ãŸLLMã§æ³¨ç›®èªã‚’æ¨è«–ã—ã¾ã™ã€‚åŒ»ç™‚é–¢é€£ã®æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚", height=150)

if st.button("æ¨è«–é–‹å§‹"):
    if not input_text.strip():
        st.warning("æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("æ¨è«–ä¸­..."):
            results = ner_predict(input_text)

        if results:
            st.markdown("### æŠ½å‡ºçµæœ")
            for word, label, score in results:
                st.markdown(f"- **{word}**  : `{label}`ï¼ˆç¢ºä¿¡åº¦: `{score:.2f}`ï¼‰")
        else:
            st.info("æ³¨ç›®èªã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
